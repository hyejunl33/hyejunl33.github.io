---
layout: single
title: "[Domain_Common_Project][ëª¨ë¸ìµœì í™”]-eval/loss vs eval/acc"
date: 2025-11-01
tags:
  - Domain_Common_Project
  - study
  - ModelOptimization
excerpt: "[ëª¨ë¸ìµœì í™”]-eval/loss vs eval/acc"
math: true
---



# Introduction

í•´ë‹¹ testì˜ í‰ê°€ ì§€í‘œëŠ” test/accì´ë‹¤. ì§€ê¸ˆê¹Œì§€ì˜ ì‹¤í—˜ ê°€ì„¤ì€ eval/lossë¥¼ ì¤„ì—¬ì„œ ê³¼ì í•©ì„ ë§‰ìœ¼ë©´ ìë™ìœ¼ë¡œ test/accë„ ì˜¬ë¼ê°ˆê²ƒì´ë¼ëŠ” ê°€ì •ì´ ìˆì—ˆë‹¤. í•˜ì§€ë§Œ eval/lossë¥¼ metricìœ¼ë¡œ ëª¨ë¸ì„ ì„ íƒí•´ì„œ testë¥¼ í•´ë³¸ ê²°ê³¼, ì„±ëŠ¥ì´ ì˜¤íˆë ¤ í•˜ë½í•˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤.

![image](/assets/images/2025-11-01-13-30-04.png)

![image](/assets/images/2025-11-01-13-30-13.png)

ê·¸ë¦¬ê³  ë‘ë²ˆì§¸ë¡œ, ëª¨ë¸ì´ ê³¼í•˜ê²Œ ì†Œìˆ˜í´ë˜ìŠ¤ë¥¼ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤. testë°ì´í„°ì…‹ì˜ ë¶„í¬ëŠ” ì•Œ ìˆ˜ ì—†ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ ì „ì²´ë°ì´í„°ì…‹ê³¼ ê°™ë‹¤ê³  ìƒê°í• ë•Œ, Focal Lossì˜ $$\alpha$$ì˜ ê°€ì¤‘ì¹˜ë¡œ ì¸í•´ ì†Œìˆ˜í´ë˜ìŠ¤ë§Œì„ ë„ˆë¬´ ì¤‘ìš”í•˜ê²Œ ì—¬ê²¨ì„œ, ì „ì²´ ë°ì´í„°ì…‹ì˜ ë¶„í¬ì™€ ì˜ˆì¸¡ ë¶„í¬ë¥¼ ë³¼ë•Œ, ì†Œìˆ˜í´ë˜ìŠ¤ì˜ ë¹„ìœ¨ì´ ê³¼ì¥ë˜ê²Œ ì˜ˆì¸¡ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.

ë”°ë¼ì„œ ì´ë²ˆì‹¤í—˜ì—ì„œëŠ” í‰ê°€ì§€í‘œë¥¼ eval/accë¡œ ë°”ê¿”ë³¸ í›„, Focal Lossì˜ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë‘ 1ë¡œ ë‘ê³  ì„±ëŠ¥ì„ ê´€ì°°í•´ë³¸ë‹¤. ì‹œê°„ê´€ê³„ìƒ ì•™ìƒë¸”í•œ ëª¨ë¸ì´ ì•„ë‹Œ ë‹¨ì¼ëª¨ë¸ë¡œ ì‹¤í—˜ì„ í•œë‹¤. í‰ê°€ì§€í‘œë¥¼ accë¡œ ë°”ê¿¨ê¸° ë•Œë¬¸ì— eval/accë§Œ ìƒìŠ¹í•˜ê³  eval/lossëŠ” í­ë°œí•˜ëŠ” ìƒí™©ì„ ë§‰ê¸° ìœ„í•´ì„œ ê¸°ì¡´ì— 8ì´ì—ˆë˜ ì—í­ì„ 5ë¡œ ì„¤ì •í•œë‹¤.

ë§Œì•½ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥í–¥ìƒì´ ìˆì„ ê²½ìš° ì´ ëª¨ë¸ì„ ê¸°ì¤€ìœ¼ë¡œ, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•œ í›„ ì•™ìƒë¸”ì„ í•´ì„œ ì„±ëŠ¥ì„ ì‹¤í—˜í•´ ë³¼ ì˜ˆì •ì´ë‹¤.

# Eval/accuracyë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì´ìš©í•˜ì..

ê¸°ì¡´ì—ëŠ” ë„ˆë¬´ ê²°ê³¼ê°€ ê³¼ì í•©ë˜ëŠ”ê²ƒ ê°™ì•„ì„œ eval/lossë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‚¬ìš©í•´ì„œ ëª¨ë¸ì„ ì„ ì •í–ˆë‹¤. ë”°ë¼ì„œ accì„±ëŠ¥ì´ ì˜ ë‚˜ì˜¤ì§€ ì•Šì€ê²ƒìœ¼ë¡œ ì¶”ì¸¡ëœë‹¤. ë”°ë¼ì„œ ì´ë²ˆì—ëŠ” eval/accuracyë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.

```python
    # --- Training Arguments for the current model ---
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=NUM_EPOCHS,
        per_device_train_batch_size=BATCH_SIZE_TRAIN,
        per_device_eval_batch_size=BATCH_SIZE_EVAL,
        warmup_steps=WARMUP_STEPS,
        weight_decay=WEIGHT_DECAY,
        learning_rate=LEARNING_RATE,
        logging_steps=100,
        eval_strategy="epoch",
        save_strategy="epoch" if SAVE_MODEL else "no",
        load_best_model_at_end=SAVE_MODEL,
        metric_for_best_model= "eval_accuracy" if SAVE_MODEL else None,
        greater_is_better=True,
        save_total_limit=SAVE_TOTAL_LIMIT_FOR_SWA if SAVE_MODEL else 0, # ìˆ˜ì •: SWA ìœ„í•´ ëŠ˜ë¦¼
        label_smoothing_factor=0.18547040498752376,
        report_to="wandb" if USE_WANDB else "none",
        run_name=run_name if USE_WANDB else None,
        seed=current_seed,
        fp16=torch.cuda.is_available(),
        dataloader_num_workers=2,
        remove_unused_columns=False,
        push_to_hub=False,
        gradient_accumulation_steps=4,
        logging_first_step=True,
        save_safetensors=SAVE_MODEL,
        lr_scheduler_type= "constant",
        # early_stopping_patience=3, # Keep early stopping if desired
        # early_stopping_threshold=0.001,
    )
```

`metric_for_best_model= "eval_accuracy"` ë¥¼ ì¸ìë¡œ ì¤˜ì„œ eval_accuracyë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ê·¸ë¦¬ê³  lossì™€ëŠ” ë‹¤ë¥´ê²Œ í¬ë©´ í´ìˆ˜ë¡ ì¢‹ì€ê²ƒì´ë¯€ë¡œ  `greater_is_better=True` ì¸ìë¥¼ Trueë¡œ ë°”ê¿”ì¤¬ë‹¤. ì´ì™€ ë”ë¶ˆì–´ì„œ Trainerë¥¼ í˜¸ì¶œí• ë•Œ `focal_loss_alpha=[1, 1, 1, 1],`  ë¥¼ ì´ìš©í•´ì„œ í´ë˜ìŠ¤ê°„ ê°€ì¤‘ì¹˜ë¥¼ ì•„ì˜ˆ ì—†ì• ë²„ë ¸ë‹¤.

# ê²°ê³¼

![image](/assets/images/2025-11-01-13-30-26.png)

ê¸°ì¡´ ì‹¤í—˜ë“¤ ì¤‘ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¸ 0.8211ì˜ accê°€ ë‚˜ì™”ë‹¤. ì´ì œ í™•ì‹¤í•œê±´, focal_lossì˜ alphaê°€ì¤‘ì¹˜ë¥¼ ì‹ ì¤‘í•˜ê²Œ ìˆ˜ì •í•´ì•¼ í•œë‹¤ëŠ”ì , ê·¸ë¦¬ê³  ëª¨ë¸ì„ ì„ ì •í• ë•ŒëŠ” ìµœì¢… testë¥¼ ìœ„í•´ì„œ accuracyë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„ ì •í•´ì•¼ í•œë‹¤ëŠ”ì ì´ í™•ì‹¤í•´ì¡Œë‹¤.

![image](/assets/images/2025-11-01-13-30-32.png)

ê¸ì •ì ì¸ ë¶€ë¶„ì€ alphaê°€ì¤‘ì¹˜ë¥¼ ëª¨ë‘ 1ë¡œ ë’€ìŒì—ë„ f1ì´ accuracyì™€ ë¹„ìŠ·í•œ ì •ë„ì˜ scoreë¥¼ ê°–ëŠ”ë‹¤ëŠ”ê²ƒì´ë‹¤. ë”°ë¼ì„œ ê°€ì¤‘ì¹˜ê°€ ëª¨ë‘ ê°™ìŒì—ë„ recallì„±ëŠ¥ì´ ë‚˜ì˜ì§€ ì•Šë‹¤ëŠ”ê²ƒìœ¼ë¡œ, alphaê°€ì¤‘ì¹˜ë¥¼ ì´ì „ì— ë°±ë¶„ìœ¨ì˜ ì—­ìˆ˜ë¡œ ì¤€ê²Œ ë§¤ìš° ì•…ì˜í–¥ì„ ë¯¸ì³¤ì—ˆë‹¤ëŠ”ê²ƒì„ ì¶”ì¸¡í•  ìˆ˜ ìˆì—ˆë‹¤.

![image](/assets/images/2025-11-01-13-30-41.png)

ëª¨ë¸ì˜ ìµœì¢… ì˜ˆì¸¡ë¶„í¬ë¥¼ ë³´ë©´ EDAí–ˆì„ë•Œ ì „ì²´ ë°ì´í„°ì…‹ì˜ ë¶„í¬ì™€ ë¹„ìŠ·í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì•½í•œ ë¶€ì •ë¹„ìœ¨ì€ ë§ì´ ë‚®ì•„ì¡Œì§€ë§Œ, ê·¸ë˜ë„ ë‹¤ìˆ˜ì˜ í´ë˜ìŠ¤ì—ì„œ Ground Truthì™€ ê°™ì€ ì •ë‹µì„ ì˜ˆì¸¡í•˜ëŠ” ìˆ«ìê°€ ëŠ˜ì–´ë‚¬ê¸° ë•Œë¬¸ì— accê°€ í–¥ìƒëœê²ƒ ê°™ë‹¤.

ì´ì „ì—ëŠ” ì´ í…ŒìŠ¤íŠ¸ì˜ ëª©í‘œëŠ” accë¥¼ ë†’ì´ëŠ”ê±´ë°, ê·¸ëŸ¬ë©´ ì°¨ë¼ë¦¬ ì†Œìˆ˜í´ë˜ìŠ¤ë¥¼ ë¬´ì‹œí•˜ê³ , recallì´ ë‚®ì•„ë„ ìƒê´€ì—†ë‹¤ëŠ” ë§ì´ë‹ˆê¹ lossëŠ” ì»¤ì§€ë”ë¼ë„ accë§Œì»¤ì§€ë©´ ë˜ë‹ˆê¹, lossëŠ” ì˜¤íˆë ¤ ì–´ëŠì •ë„ëŠ” ì»¤ì ¸ë„ ìƒê´€ì—†ì„ê²ƒ ê°™ë‹¤ê³  ìƒê°ì„ í–ˆë‹¤. í•˜ì§€ë§Œ f1 scoreì™€ accê°€ ë™ì‹œì— ì˜¬ë¼ê°€ëŠ” ê²°ê³¼ë¥¼ ê´€ì¸¡í•  ìˆ˜ ìˆì—ˆë‹¤.

ì´ì œ ë‚¨ì€ê²ƒì€ BERTê¸°ë°˜ ëª¨ë¸ 3ê°œì˜ ì•™ìƒë¸”ì„ í†µí•œ ëª¨ë¸ì´ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³ , í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•´ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì„±ëŠ¥ì„ ë½‘ì•„ë‚´ëŠ”ê²ƒì´ë‹¤.

## BERTê¸°ë°˜ ëª¨ë¸ 3ê°œ ì•™ìƒë¸”

```python
# === Ensemble Training Block ===
# Replace the original training cell (ID: 176174ee) with this code.

# --- Model Training Settings ---
SAVE_MODEL = True
USE_WANDB = True # Set to True if you want to use Weights & Biases logging for each model
from transformers import EarlyStoppingCallback 
# List of models for ensemble
model_names = [
    # "./tapted_klue_roberta_base",
    "./tapted_klue_bert_base",
    "./tapted_kykim_bert_kor_base",
    "./tapted_beomi_kcbert_base"
    # "./tapted_koelectra_base_v3"
]

# --- Loop through each model for training ---
all_training_results = {}

for model_name in model_names:
    current_seed = random.randint(1, 100000)
    model_short_name = model_name.split('/')[-1].replace('-', '_') # Create a short name for directories/logging
    output_dir = f"./results_{model_short_name}"
    run_name = f"{model_short_name}-movie-review"

    print("\n" + "=" * 50)
    print(f"ëª¨ë¸ í›ˆë ¨ ì‹œì‘: {model_name}")
    print(f"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_dir}")
    print(f"í˜„ì¬ ì‹œë“œê°’: {current_seed}") # ğŸ’¡ í˜„ì¬ ì‹œë“œê°’ ì¶œë ¥
    print("=" * 50)

    # --- Load Model and Tokenizer for the current model ---
    try:
        current_tokenizer = AutoTokenizer.from_pretrained(model_name)
        current_model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=NUM_CLASSES,
        )
        current_model.to(device) # Move model to GPU

        # --- Add new special tokens and resize embeddings ---
        num_added_toks = current_tokenizer.add_tokens(NEW_SPECIAL_TOKENS)
        if num_added_toks > 0:
            print(f"Added {num_added_toks} new special tokens for {model_name}.")
            current_model.resize_token_embeddings(len(current_tokenizer))
            print("Resized model token embeddings.")

    except Exception as e:
        print(f"Error loading model {model_name}: {e}")
        print("Skipping this model.")
        continue # Skip to the next model if loading fails

    # --- Recreate Datasets with the current tokenizer ---
    # This is necessary because different models might have different tokenization
    train_dataset_current = ReviewDataset(
        train_data["review"],
        train_data["label"],
        current_tokenizer,
        CHOSEN_MAX_LENGTH,
    )
    val_dataset_current = ReviewDataset(
        val_data["review"],
        val_data["label"],
        current_tokenizer,
        CHOSEN_MAX_LENGTH,
    )
    
    # SWA ì„¤ì • ì¶”ê°€
    SWA_K = 2 # í‰ê· ë‚¼ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ ê°œìˆ˜
    SAVE_TOTAL_LIMIT_FOR_SWA = SWA_K + 1 # best ëª¨ë¸ + ë§ˆì§€ë§‰ Kê°œ ì €ì¥ë˜ë„ë¡ (ìµœì†Œ 2)

    # --- Training Arguments for the current model ---
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=NUM_EPOCHS,
        per_device_train_batch_size=BATCH_SIZE_TRAIN,
        per_device_eval_batch_size=BATCH_SIZE_EVAL,
        warmup_steps=WARMUP_STEPS,
        weight_decay=WEIGHT_DECAY,
        learning_rate=LEARNING_RATE,
        logging_steps=100,
        eval_strategy="epoch",
        save_strategy="epoch" if SAVE_MODEL else "no",
        load_best_model_at_end=SAVE_MODEL,
        metric_for_best_model= "eval_accuracy" if SAVE_MODEL else None,
        greater_is_better=True,
        save_total_limit=SAVE_TOTAL_LIMIT_FOR_SWA if SAVE_MODEL else 0, # ìˆ˜ì •: SWA ìœ„í•´ ëŠ˜ë¦¼
        label_smoothing_factor=0.18547040498752376,
        report_to="wandb" if USE_WANDB else "none",
        run_name=run_name if USE_WANDB else None,
        seed=current_seed,
        fp16=torch.cuda.is_available(),
        dataloader_num_workers=2,
        remove_unused_columns=False,
        push_to_hub=False,
        gradient_accumulation_steps=4,
        logging_first_step=True,
        save_safetensors=SAVE_MODEL,
        lr_scheduler_type= "constant",
        # early_stopping_patience=3, # Keep early stopping if desired
        # early_stopping_threshold=0.001,
    )
    early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3) # <--- ì›í•˜ëŠ” patience ê°’
    # --- Initialize Trainer for the current model ---
    trainer = CustomTrainerWithFocalLoss(
        model=current_model,
        args=training_args,
        train_dataset=train_dataset_current,
        eval_dataset=val_dataset_current,
        # tokenizer=current_tokenizer,
        num_classes=NUM_CLASSES,
        callbacks=[early_stopping_callback],
        focal_loss_alpha=[1, 1, 1, 1], # Adjust alpha if needed
        focal_loss_gamma=2.965201490877045,
        data_collator=DataCollatorWithPadding(tokenizer=current_tokenizer),
        compute_metrics=compute_metrics,
    )
```

```python
    # --- Training Execution ---
    print(f"í›ˆë ¨ ì •ë³´ ({model_name}):")
    print(f"  í›ˆë ¨ ìƒ˜í”Œ: {len(train_dataset_current):,}ê°œ")
    print(f"  ê²€ì¦ ìƒ˜í”Œ: {len(val_dataset_current):,}ê°œ")
    print(f"  í›ˆë ¨ ì—í¬í¬: {training_args.num_train_epochs}íšŒ")
    print(f"  ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE_TRAIN} (í›ˆë ¨) / {BATCH_SIZE_EVAL} (ê²€ì¦)")
    print(f"  í•™ìŠµë¥ : {LEARNING_RATE}")
    print(f"  ì‹œë“œê°’: {current_seed}")
    print(f"  ë””ë°”ì´ìŠ¤: {device}")
    print(f"  wandb ì‚¬ìš©: {USE_WANDB}")

    try:
        training_result = trainer.train()
        print(f"\n{model_name} í›ˆë ¨ ì™„ë£Œ")
        print(f"  ìµœì¢… í›ˆë ¨ ì†ì‹¤: {training_result.training_loss:.4f}")
        all_training_results[model_name] = training_result

        # --- Save the final best model ---
        if SAVE_MODEL:
            best_model_path = f"{output_dir}/best_model_{model_short_name}"
            print(f"ìµœì¢… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ì¤‘: {best_model_path}")
            trainer.save_model(best_model_path)
            current_tokenizer.save_pretrained(best_model_path)
            print(f"ìµœì¢… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {best_model_path}")

            
            # === SWA (Stochastic Weight Averaging) ì ìš© ì‹œì‘ ===
            print(f"\n--- SWA ê°€ì¤‘ì¹˜ í‰ê·  ì‹œì‘ (ëª¨ë¸: {model_name}) ---")
            print(f"ë§ˆì§€ë§‰ {SWA_K}ê°œ ì²´í¬í¬ì¸íŠ¸ë¥¼ í‰ê· ëƒ…ë‹ˆë‹¤.")

            try:
                # 1. SWAì— ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸°
                checkpoint_dir = output_dir
                checkpoints = sorted(
                    glob.glob(os.path.join(checkpoint_dir, "checkpoint-*")),
                    key=lambda x: int(x.split('-')[-1]) # ìŠ¤í… ë²ˆí˜¸ ê¸°ì¤€ ì •ë ¬
                )

                if len(checkpoints) >= SWA_K:
                    swa_checkpoints = checkpoints[-SWA_K:]
                    print(f"SWAì— ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸ ({len(swa_checkpoints)}ê°œ):")
                    for ckpt in swa_checkpoints:
                        print(f" - {os.path.basename(ckpt)}")

                    # 2. ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ (êµ¬ì¡°ë§Œ ì‚¬ìš©)
                    # best_model_pathì—ì„œ configë¥¼ ë¡œë“œí•˜ì—¬ ë™ì¼í•œ êµ¬ì¡° ë³´ì¥
                    print("SWA ê¸°ë³¸ ëª¨ë¸ êµ¬ì¡° ë¡œë”© ì¤‘...")
                    config = AutoConfig.from_pretrained(best_model_path)
                    swa_base_model = AutoModelForSequenceClassification.from_config(config)
                    swa_base_model.to(device)

                    # 3. ê°€ì¤‘ì¹˜ í‰ê· ë‚´ê¸°
                    print("ì²´í¬í¬ì¸íŠ¸ ê°€ì¤‘ì¹˜ í‰ê·  ê³„ì‚° ì¤‘...")
                    avg_state_dict = OrderedDict()
                    model_keys = swa_base_model.state_dict().keys() # ëª¨ë¸ í‚¤ ì €ì¥

                    for i, checkpoint_path in enumerate(swa_checkpoints):
                        print(f"  ({i+1}/{len(swa_checkpoints)}) ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: {checkpoint_path}")
                        # safetensors ìš°ì„  ë¡œë“œ ì‹œë„
                        safetensors_path = os.path.join(checkpoint_path, "model.safetensors")
                        bin_path = os.path.join(checkpoint_path, "pytorch_model.bin")

                        if os.path.exists(safetensors_path):
                            state_dict = load_safetensors_file(safetensors_path, device="cpu")
                        elif os.path.exists(bin_path):
                            state_dict = torch.load(bin_path, map_location="cpu")
                        else:
                            print(f"  ê²½ê³ : {checkpoint_path} ì—ì„œ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆ<0xEB><0x9A><0x8D>ë‹ˆë‹¤.")
                            continue

                        # í‰ê·  ê³„ì‚° (ì²« ë²ˆì§¸ ì²´í¬í¬ì¸íŠ¸ëŠ” ë³µì‚¬, ì´í›„ëŠ” ë”í•˜ê¸°)
                        for key in model_keys:
                            if key not in state_dict:
                                print(f"  ê²½ê³ : í‚¤ '{key}'ê°€ ì²´í¬í¬ì¸íŠ¸ì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆ<0xEB><0x9A><0x8D>ë‹ˆë‹¤.")
                                continue
                            if i == 0:
                                avg_state_dict[key] = state_dict[key].clone().float() # float()ë¡œ íƒ€ì… í†µì¼
                            else:
                                if key in avg_state_dict:
                                     avg_state_dict[key] += state_dict[key].float() # float()ë¡œ íƒ€ì… í†µì¼
                                else:
                                     print(f"  ê²½ê³ : ì´ì „ ì²´í¬í¬ì¸íŠ¸ì— ì—†ë˜ í‚¤ '{key}' ë°œê²¬. ê±´ë„ˆ<0xEB><0x9A><0x8D>ë‹ˆë‹¤.")

                        del state_dict # ë©”ëª¨ë¦¬ í™•ë³´

                    # í‰ê·  ê³„ì‚° (Kë¡œ ë‚˜ëˆ„ê¸°)
                    num_averaged = len(swa_checkpoints) # ì‹¤ì œ ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸ ìˆ˜
                    if num_averaged > 0:
                        for key in avg_state_dict:
                            avg_state_dict[key] /= num_averaged

                        # 4. í‰ê· ë‚¸ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì— ë¡œë“œ
                        missing_keys, unexpected_keys = swa_base_model.load_state_dict(avg_state_dict, strict=False)
                        if missing_keys: print(f"  ê²½ê³ : ë¡œë“œë˜ì§€ ì•Šì€ í‚¤: {missing_keys}")
                        if unexpected_keys: print(f"  ê²½ê³ : ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {unexpected_keys}")
                        print("í‰ê·  ê°€ì¤‘ì¹˜ ëª¨ë¸ì— ë¡œë“œ ì™„ë£Œ.")

                        # 5. ë°°ì¹˜ ì •ê·œí™”(Batch Normalization) í†µê³„ ì—…ë°ì´íŠ¸ (ë§¤ìš° ì¤‘ìš”!)
                        print("ë°°ì¹˜ ì •ê·œí™” í†µê³„ ì—…ë°ì´íŠ¸ ì¤‘...")
                        # update_bn í•¨ìˆ˜ëŠ” DataLoaderê°€ í•„ìš”
                        swa_data_collator = DataCollatorWithPadding(tokenizer=current_tokenizer)
                        train_dataloader_for_bn = DataLoader(
                            train_dataset_current,
                            batch_size=BATCH_SIZE_TRAIN, # í›ˆë ¨ ë°°ì¹˜ í¬ê¸° ì‚¬ìš© ê¶Œì¥
                            collate_fn=swa_data_collator,
                            shuffle=False, # BN ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” ì…”í”Œ ë¶ˆí•„ìš”
                            num_workers=2
                        )
                        # update_bn í•¨ìˆ˜ í˜¸ì¶œ
                        # swa_utils.update_bn()ì€ AveragedModel ê°ì²´ë¥¼ ë°›ì§€ë§Œ,
                        # ì—¬ê¸°ì„œëŠ” ì§ì ‘ í‰ê· ë‚¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, ìˆ˜ë™ ë£¨í”„ ë˜ëŠ” ì•„ë˜ì™€ ê°™ì´ ì§ì ‘ í˜¸ì¶œ
                        swa_base_model.train() # BN ì—…ë°ì´íŠ¸ëŠ” train ëª¨ë“œì—ì„œ
                        with torch.no_grad():
                            num_batches_tracked = 0
                            for batch in tqdm(train_dataloader_for_bn, desc="BN ì—…ë°ì´íŠ¸", leave=False):
                                inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'token_type_ids']}
                                if not inputs: continue # ì…ë ¥ì´ ì—†ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
                                swa_base_model(**inputs)
                                num_batches_tracked += 1
                                if num_batches_tracked >= 100: # ì „ì²´ ë°ì´í„° ëŒ€ì‹  ì¼ë¶€(ì˜ˆ: 100 ë°°ì¹˜)ë§Œ ì‚¬ìš©í•´ë„ ì¶©ë¶„í•  ìˆ˜ ìˆìŒ
                                    break
                        swa_base_model.eval() # ë‹¤ì‹œ eval ëª¨ë“œë¡œ
                        print(f"ë°°ì¹˜ ì •ê·œí™” í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì•½ {num_batches_tracked} ë°°ì¹˜ ì‚¬ìš©).")

                        # 6. SWA ëª¨ë¸ ì €ì¥
                        swa_model_path = f"{output_dir}/swa_model_{model_short_name}"
                        os.makedirs(swa_model_path, exist_ok=True)
                        print(f"SWA ëª¨ë¸ ì €ì¥ ì¤‘: {swa_model_path}")
                        # state_dict() ì €ì¥ ë°©ì‹ ì‚¬ìš©
                        torch.save(swa_base_model.state_dict(), os.path.join(swa_model_path, "pytorch_model.bin"))
                        # save_pretrainedëŠ” ì „ì²´ ëª¨ë¸ ê°ì²´ë¥¼ ì €ì¥í•˜ë ¤ í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” state_dict ì €ì¥ ê¶Œì¥
                        # swa_base_model.save_pretrained(swa_model_path) # í•„ìš”ì‹œ ì‚¬ìš© ê°€ëŠ¥
                        current_tokenizer.save_pretrained(swa_model_path) # í† í¬ë‚˜ì´ì €ë„ í•¨ê»˜ ì €ì¥
                        # config.jsonë„ ì €ì¥ (save_pretrainedê°€ ì—†ìœ¼ë¯€ë¡œ ìˆ˜ë™ ë³µì‚¬ ë˜ëŠ” ì €ì¥)
                        config.save_pretrained(swa_model_path)

                        print(f"SWA ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {swa_model_path}")

                    else:
                        print("í‰ê· ë‚¼ ìœ íš¨í•œ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

                else:
                    print(f"SWAë¥¼ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ ({len(checkpoints)}ê°œ ë°œê²¬, {SWA_K}ê°œ í•„ìš”). SWAë¥¼ ê±´ë„ˆ<0xEB><0x9A><0x8D>ë‹ˆë‹¤.")

            except Exception as e:
                print(f"SWA ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            finally:
                # SWA ëª¨ë¸ ê°ì²´ ë©”ëª¨ë¦¬ ì •ë¦¬ (í•„ìš”ì‹œ)
                if 'swa_base_model' in locals():
                    del swa_base_model
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            print("--- SWA ê°€ì¤‘ì¹˜ í‰ê·  ì¢…ë£Œ ---")
        # === SWA ì ìš© ì¢…ë£Œ ===
        
        
    except KeyboardInterrupt:
        print(f"\nì‚¬ìš©ìì— ì˜í•´ {model_name} í›ˆë ¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # Optionally break the loop if one model training is interrupted
        # break
    except Exception as e:
        print(f"\n{model_name} í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # Optionally log the error and continue with the next model
        # continue

    # --- Clean up GPU memory before next model ---
    del current_model
    del current_tokenizer
    del trainer
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

print("\n" + "=" * 50)
print("ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
print("=" * 50)

```

ìš°ì„  ì•™ìƒë¸”í•  ê° ëª¨ë¸ë§ˆë‹¤ ëœë¤ì‹œë“œë¥¼ ë‹¤ë¥´ê²Œì£¼ë„ë¡ êµ¬í˜„í•´ì„œ ëª¨ë¸ë“¤ì´ ë³´ëŠ” ë°ì´í„°ì…‹ì˜ ë¶„ì‚°ì„ í‚¤ìš°ê³ ì í–ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì•™ìƒë¸”ì˜ íš¨ê³¼ëŠ” ê° ëª¨ë¸ì´ ìƒì´í•œ ë¶€ë¶„ì—ì„œ í•˜ëŠ” ì‹¤ìˆ˜ë¥¼ ë§¤ê¿€ë•Œ ê·¹ëŒ€í™” ë˜ë¯€ë¡œ ì„œë¡œë‹¤ë¥¸ ëª¨ë¸ì´ í•™ìŠµí• ë•Œë§ˆë‹¤ ë£¨í”„ì•ˆì—ì„œ ë‹¤ë¥¸ ëœë¤ì‹œë“œë¥¼ ê°€ì§€ë„ë¡ ì½”ë“œë¡œ êµ¬í˜„í–ˆë‹¤.

### ì•™ìƒë¸”í•œ ê²°ê³¼

![image](/assets/images/2025-11-01-13-30-56.png)

ëª¨ë¸ 3ê°œë¥¼ ì•™ìƒë¸”í•œ ê²°ê³¼ accê°€ 0.7% ì˜¬ëë‹¤. ì¦‰ ìœ ì˜ë¯¸í•œ íš¨ê³¼ê°€ ìˆì—ˆë‹¤.

![image](/assets/images/2025-11-01-13-31-02.png)

ì´ì „ ì‹¤í—˜ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ìµœì¢… ì˜ˆì¸¡ë¶„í¬ë¥¼ ë³´ë©´ ì „ì²´ ë°ì´í„°ì…‹ì˜ ë¶„í¬ì™€ ë¹„ìŠ·í•˜ê²Œ ë§ì¶¤ì„ ì•Œ ìˆ˜ ìˆë‹¤. accë¥¼ ë†’ì´ë ¤ë©´ test ë°ì´í„°ì˜ ë¶„í¬ì™€ ìœ ì‚¬í•´ì•¼í•¨ì„ ì‹œì‚¬í•œë‹¤. ê·¸ë¦¬ê³  ì†Œìˆ˜ë¥¼ ì°¨ì§€í•˜ëŠ” ë¶„í¬ì¸ ì•½í•œë¶€ì •ì€ ë” ëœë§ì¶”ëŠ” ê²½í–¥ì„±ì´ ìˆì§€ë§Œ, 0,1,3ë ˆì´ë¸”ì€ ë” ì •êµí•˜ê²Œ ì›ë˜ ë°ì´í„°ë¶„í¬ì™€ ë¹„ìŠ·í•´ì¡ŒìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ëŒ€ë‹¤ìˆ˜ì˜ ë ˆì´ë¸”ì„ ì˜ ëª»ì¶”ë©´ ì—­ì‹œ accê°€ ì˜¬ë¼ê°ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.

# ì´í›„ ì‹¤í—˜ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ê²ƒë“¤

- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
    - Focal Lossì—ì„œ ì•ŒíŒŒ ê°€ì¤‘ì¹˜ë¥¼ ì–¼ë§ˆë‚˜ ì¤˜ì•¼í• ê¹Œ?
        - ìµœì ì˜ ì•ŒíŒŒ ê°€ì¤‘ì¹˜ëŠ” ì–¼ë§ˆì¼ê¹Œ?
    - ì´ì™¸ì— í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹í•  ìˆ˜ ìˆëŠ”ê°’ ëª¨ë‘ ë„£ê¸°
- valid ë°ì´í„°ë¥¼ í¬í•¨í•´ì„œ ì „ì²´ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµì‹œì¼œë³´ê¸°
- ëª¨ë¸ ì•™ìƒë¸” ì¶”ë¡ ì„ í• ë•Œ, ëª¨ë¸ë³„ë¡œ Weightë¥¼ ì¤˜ì„œ ì•™ìƒë¸”ì„ í•´ë³´ê¸°